{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5da6ec04-e211-4d7c-b26f-5f6250ef192f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.12'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from platform import python_version\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e23294f-ceb6-416e-8177-36218f7ec25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/John/opt/anaconda3/lib/python3.9/site-packages (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/John/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/John/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/John/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/John/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "# If you know for sure your python3 is the right version, give this a try\n",
    "!python3.9 -m pip install -U scikit-learn\n",
    "\n",
    "# I have four different versions of python on my machine so I have to \n",
    "# replace python3 with python3.9.\n",
    "# You might be able to do it just with python, but python3 usually works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5719123-ae48-462a-8d99-546e001eb628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f1039e1-bdce-4be4-817d-268bd945cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## word count vectors are contained in the file out.csv, got from the NaiveExtraction file\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "temp = []\n",
    "nptarget = []\n",
    "\n",
    "file = open('out.csv')\n",
    "csvreader = csv.reader(file)\n",
    "\n",
    "header = []\n",
    "header = next(csvreader)\n",
    "\n",
    "rows = []\n",
    "r2 = []\n",
    "temp2 = []\n",
    "\n",
    "for row in csvreader:\n",
    "        rows.append(row)\n",
    "\n",
    "for x in temp:\n",
    "    nptarget.append(0)\n",
    "    \n",
    "\n",
    "npdata = []\n",
    "for i in rows:\n",
    "    newTemp = []\n",
    "    for x in i:\n",
    "        newTemp.append(int(x))\n",
    "        \n",
    "    npdata.append(newTemp)\n",
    "        \n",
    "\n",
    "# new approach - just need to make the actual arrays, then shape with numpy\n",
    "\n",
    "    \n",
    "npdata = np.array(npdata)\n",
    "nptarget = np.array(nptarget)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c648ffc7-1529-4070-919f-d44ed06a1baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2417\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(npdata))\n",
    "print(len(nptarget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f615d371-5f2d-4fe7-9436-5bf010318172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data for target\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "allTrainData = []\n",
    "with open('trainDataBetter.csv','rt')as f:\n",
    "  data = csv.reader(f)\n",
    "  for row in data:\n",
    "        allTrainData.append(row)\n",
    "        \n",
    "        \n",
    "# train and target to boe the same size\n",
    "# define the training set\n",
    "nptarget = []\n",
    "\n",
    "for i in allTrainData[1:]:\n",
    "    nptarget.append(i[1])\n",
    "\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef2a050a-516b-4a95-acf9-07c4757b0c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "nptarget = nptarget[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56569a83-db6a-462d-b728-a04412f18468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2417\n",
      "2417\n"
     ]
    }
   ],
   "source": [
    "print(len(npdata))\n",
    "print(len(nptarget))\n",
    "\n",
    "# creating intergers np type instead of float\n",
    "nptarget2 = []\n",
    "for i in nptarget:\n",
    "    nptarget2.append(int(i))\n",
    "    \n",
    "nptarget = np.array(nptarget2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a7849c2-0982-4264-aa33-8d9dcdfa29a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have  2417 training instances\n",
      "You have  24155 features\n",
      "npdata\n",
      "(2417, 24155)\n",
      "nptarget\n",
      "(2417,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# printing instances and features\n",
    "print(\"You have \", npdata.shape[0], \"training instances\")\n",
    "print(\"You have \", npdata.shape[1], \"features\")\n",
    "print(\"npdata\")\n",
    "print(npdata.shape)\n",
    "print(\"nptarget\")\n",
    "print(nptarget.shape)\n",
    "print(type(nptarget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6457225-f346-4049-b094-f9580a3bd599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "0\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "print(npdata[0])\n",
    "print(nptarget[0])\n",
    "print(type(npdata[0][0]))\n",
    "print(type(nptarget[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a56b684-5a75-447c-bf1f-c78c9ab2ee62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- most_frequent ---\n",
      "fit_time 0.2292144775390625\n",
      "score_time 0.0032637596130371095\n",
      "test_accuracy 0.5262717519634516\n",
      "test_precision 0.5262717519634516\n",
      "test_recall 1.0\n",
      "test_f1 0.6896172355102332\n",
      "--- stratified ---\n",
      "fit_time 0.2075416088104248\n",
      "score_time 0.003600311279296875\n",
      "test_accuracy 0.49233954451345757\n",
      "test_precision 0.5176501031418609\n",
      "test_recall 0.5180855334259687\n",
      "test_f1 0.5177960518284975\n",
      "--- uniform ---\n",
      "fit_time 0.21147308349609376\n",
      "score_time 0.0033374309539794924\n",
      "test_accuracy 0.48819533562616557\n",
      "test_precision 0.5147805077522059\n",
      "test_recall 0.486648139570789\n",
      "test_f1 0.4997836980800107\n"
     ]
    }
   ],
   "source": [
    "# These are the scoring metrics we will consider\n",
    "scoring_metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Here we are looping throught our three favorite naive baselines\n",
    "for s in [\"most_frequent\", \"stratified\", \"uniform\"]:\n",
    "    print(\"---\", s, \"---\")\n",
    "    \n",
    "    # initialize the classifier\n",
    "    dummy_classifier = DummyClassifier(strategy=s,random_state=None)\n",
    "\n",
    "    # run the classifier for each fold, where the number of folds is 5\n",
    "    scores = cross_validate(dummy_classifier, npdata, nptarget, cv=5, scoring=scoring_metrics)\n",
    "\n",
    "    # print out the mean of each scoring metric\n",
    "    for score_name, score_value in scores.items():\n",
    "        print(score_name, score_value.mean())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca7a91c9-19de-4d1e-827b-1f0564d211dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [1.2131319  1.14425492 1.08387399 1.14117503 1.1441009 ]\n",
      "score_time [0.19662404 0.11072612 0.12697911 0.12541199 0.12714481]\n",
      "test_accuracy [0.58884298 0.61363636 0.62318841 0.69565217 0.68530021]\n",
      "test_precision [0.59655172 0.60493827 0.63138686 0.66563467 0.66887417]\n",
      "test_recall [0.67843137 0.76862745 0.68110236 0.84645669 0.79527559]\n",
      "test_f1 [0.63486239 0.67702936 0.65530303 0.74523397 0.72661871]\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "\n",
    "# Let's train a model with 5-fold cross validation.\n",
    "scores = cross_validate(gnb, npdata, nptarget, cv=5, scoring=scoring_metrics)\n",
    "\n",
    "# Then we print out each of the metrics for each of the 5 folds.\n",
    "for score_name, score_value in scores.items():\n",
    "    print(score_name, score_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3233e5-47e7-458a-95a3-c01caca548ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
